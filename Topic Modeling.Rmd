---
title: "Topic Modeling"
output: html_document
date: "2022-11-13"
author: "Qihan Su,Ziyang Lin, Runze Pang, Lanlin Zhao"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## **Introduction:**

Topic modeling is a method to find topics which are operationalized as bundles of correlating terms in documents to see what the texts are about. In this project, IMDB Dataset is the target for our analysis. This dataset includes 50K movie reviews for natural language processing or text analytics. The topic modeling includes data cleaning procedures with utilization of tf-idf and LDA to find mixtures of words in different topics, contexts or documents. After that, terms within each topic are extracted and plotted to help understand the representation of these topics. 
## **Preparation:**

```{r}
library(topicmodels)
library(tidytext)
library(tidyverse)
library(tidytext)
library(ggplot2)
library(ggthemes)
library(dplyr)
library(corrplot)
library(PerformanceAnalytics)
library(knitr)
library(stringr)
library(stringi)
library(tm)
library(tidyr)
library(tokenizers)
library(widyr)
library(igraph)
library(ggraph)
```

```{r}
IMDB <- read.csv("D:/Rresources/IMDB Dataset.csv")
IMDB_df <- tibble(IMDB)
glimpse(IMDB_df)
head(IMDB_df)
#Assign an id to each review
IMDB_df %>% 
  mutate(review_number = row_number()) ->IMDB_df 
#Focus on review
IMDB_df <- IMDB_df %>% select(-sentiment)
```

##Analize word and document frequncy :tf-idf

```{r}
IMDB <- IMDB  %>%  mutate(docs = c(1:length(IMDB$review)))
book_words <- IMDB %>%
  unnest_tokens(word, review) %>%
  anti_join(stop_words)%>%
  count(docs, word, sort = TRUE)

total_words <- book_words %>% 
  group_by(docs) %>% 
  summarize(total = sum(n))

book_words <- left_join(book_words, total_words)

freq_by_rank <- book_words %>% 
  group_by(docs) %>% 
  mutate(rank = row_number(), 
         `term frequency` = n/total) %>%
  ungroup()

book_tf_idf <- book_words %>%
  bind_tf_idf(word, docs, n)


```

##According to the tf-idf, select extra stop words

```{r}
#check the range of tf-idf of all words(default stop words already excluded)
range(book_tf_idf$tf_idf)
#The tf-idf value can help us exclude the words that have high frequency but too common in overall movie reviews
#We find the range of tf-idf is between 0.0005477301 and 5.5159653999. Thus, exclude those words with tf-idf less than 0.003 can be reasonable (fot the ti-idf is log based). 
my_stopwords<-tibble(word = levels(as.factor(book_tf_idf$word[book_tf_idf$tf_idf < 0.003])))
my_stopwords$lexicon<-"SMART"
my_stopwords<-rbind(stop_words,my_stopwords)

#We add 88 extra words



#Add other words that we consider meaningless to the stop words. 

my_stopwords <- rbind(my_stopwords,c("tells","SMART"))%>%rbind(c("type","Smart"))%>%rbind(c("film","SMART"))%>%rbind(c("match","SMART"))%>%rbind(c("stop.oz","SMART"))%>%rbind(c("style","SMART"))%>%rbind(c("episode","SMART"))%>%
rbind(c("series","SMART"))%>%rbind(c("season","SMART"))%>%rbind(c("version","SMART"))%>%rbind(c("5","SMART"))%>%rbind(c("10","SMART"))%>%rbind(c("1","SMART"))%>%rbind(c("character","SMART"))%>%rbind(c("characters","SMART"))%>%rbind(c("scenes","SMART"))%>%rbind(c("scene","SMART"))%>%rbind(c("story","SMART"))%>%rbind(c("films","SMART"))%>%rbind(c("director","SMART"))%>%rbind(c("time","SMART"))%>%rbind(c("film's","SMART"))%>%rbind(c("watching","SMART"))%>%rbind(c("feel","SMART"))%>%rbind(c("role","SMART"))
```

### LDA

```{r}
#Exclued the extra stop words and get a DocumentTermMatrix of IMDB

IMDB_dtm <- IMDB %>%
  unnest_tokens(word, review) %>%
  anti_join(stop_words)%>%
  count(docs, word) %>%
  cast_dtm(docs, word, n)
```

```{r}
#Set k = 10 try to divide these reviews into 10 topics and specify a seed for reproducibility
ap_lda <- LDA(IMDB_dtm, k = 10, control = list(seed = 1234))

ap_topics <- tidy(ap_lda, matrix = "beta")

ap_top_terms <- ap_topics %>%
  group_by(topic) %>%
  slice_max(beta, n = 10) %>% 
  ungroup() %>%
  arrange(topic, -beta)
ap_top_terms

ap_top_terms %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(beta, term, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  scale_y_reordered()
```

##As we can see from the gragh, ten themes can be extracted from the text. Here we take some topics as example:

### For topic 1, the most common words include "dead","horror","war",and "hope". This topic could represent a series of war movies.

### For topic 2, the most common words include "life","comedy", and "family". This topic could represent some some family comedies.


##Document classification

### Next, we try to find out whether our model fits good.

```{r}
ap_documents <- tidy(ap_lda, matrix = "gamma")
# ap_documents
ap_documents <- ap_documents %>%
  separate(document, c("title"),sep = "_", convert = TRUE)
ap_documents

ggplot(ap_documents, aes(gamma)) +
  geom_histogram(alpha = 0.8) +
  scale_y_log10() +
  labs(title = "Distribution of probabilities for all topics",
       y = "Number of documents", x = expression(gamma))
```

```{r}
ggplot(ap_documents, aes(x = gamma , fill = as.factor(topic))) + geom_histogram()+
  facet_wrap(~topic, ncol = 3) + 
  scale_y_log10() +
  labs(title = "per-document-per-topic probabilities",
       y = "documents number",
       x= "gamma"
       )
```

##It can be seen that the overall distribution and distribitions for each topic are right skewed. These graphs show a vague result of topic distribution. The probabilities are centered at about 0.1 which means we have a little confifence to assign a movie to a certain topic.

##From the ten chart above, howerer, we can still see that the document 3 differs the most from other documents. In order to check this, we tidy the document 3 and to see the most common words in it.

```{r}
ggplot(ap_documents, aes(factor(topic),gamma ))+ geom_boxplot()+
  labs(title = "per-document-per-topic probabilities",
       y = "gamma",
       x= "topic"
       )
```

##Tidy document 3

```{r}
tidy(IMDB_dtm) %>%
  filter(document == 3) %>%
  arrange(desc(count))
```

## word topic probability

```{r}
beta_wide <- ap_topics %>%
  mutate(topic = paste0("topic", topic)) %>%
  pivot_wider(names_from = topic, values_from = beta) %>% 
  filter(topic3 > .001 | topic4 > .001) %>%
  mutate(log_ratio = log2(topic3 / topic4))
beta_wide
```

##Comparing two topics' top ten frequncy words between topic 3 and 4

```{r}
beta_wide %>% 
group_by(direction = log_ratio > 0) %>% 
slice_max(abs(log_ratio), n = 10) %>%  
ungroup() %>% 
mutate(term = reorder(term, log_ratio)) %>% 
ggplot(aes(log_ratio, term)) + 
geom_col() + 
labs(x = "Log2 ratio of beta in topic 3 / topic 4", y = NULL)
```

##From the ten 'gamma chart' above, we knew that the documents 3 differs the most, and it seems that document 2,4,5,9,10 are the most common documents so we select document 4 to comapre with 3. As we can see, the topic 3 was talking some crime movies, while topic 4 was about comedy.

##Classification in topic

### Next, we check the the reviews which have the highest gamma in each topic

```{r}
chapter_classifications <- ap_documents %>%
  group_by(topic) %>%
  slice_max(gamma) %>%
  ungroup()

chapter_classifications
```

### The 28690th review got a gamma of 0.234 in topic 1, as we expected, it should be a review about some horror or war movies. 

### The original text of the book review is:

#### These guys are excellent and anything they put out to the public is first class. The musicianship of this band is amazing... Future generations will never be able to see such mastery live and in person. Get this DVD and you will enjoy it throughly!! ...

### This review definitely comes for a music related movie. This is an incorrect estimate of the model.



##Co-occurence network

```{r}

IMDB_words <- IMDB %>%
  unnest_tokens(word, review) %>%
  anti_join(my_stopwords)%>%
  count(docs, word)

word_pairs <- IMDB_words %>% 
  pairwise_count(word,docs, sort = TRUE, upper = FALSE)
```

```{r}

set.seed(1234)
word_pairs %>%
  filter(n >= 800) %>%
  graph_from_data_frame() %>%
  ggraph(layout = "fr") +
  geom_edge_link(aes(edge_alpha = n, edge_width = n), edge_colour = "cyan4") +
  geom_node_point(size = 5) +
  geom_node_text(aes(label = name), repel = TRUE, 
                 point.padding = unit(0.2, "lines")) +
  theme_void()
```


## We see clustering from above figure. It shows strong connections between the bottom right words. They are all connected to "life". And there are also 4 small clusters like "white","black" and "book", "read".


# **Conclusion:**

## In this project, We assumed that the topic of this dataset is separated by the type of the movie. To test our hypothesis, we were trying to make 10 topics.we found that the topics are vaguely generalized. We also tried other number of topics(from 2 to 15), the result is still not ideal. The gamma distribution even approachs to normal distribution when k = 2. The test results cannot support our hypothesis that the movie reviews are separated by movie type. There may be many reasons for this. For example, people's reviews of movies can be very subjective. When expressing people their views, they are likely to use a large number of non-movie related words to express their feelings which is likely to make the model to give a dubious result.

